<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用docker创建mysql容器]]></title>
    <url>%2F2019%2F03%2F10%2Fdocker%2F%E4%BD%BF%E7%94%A8docker%E5%88%9B%E5%BB%BAmysql%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[我们在工作中会有需要在本机安装mysql，但是独立去安装mysql会耗费很大的内存以及磁盘空间，如果是在自己的电脑上时间久了可能会使电脑越来越卡。如果我们购买了云主机，我们可以在主机上自己按住mysql，但是普通的按住步骤太繁琐，而且一般只能启用一个mysql，这时候Docker就站出来啦。个人比较推荐使用docker，因为真的是太好用了，好用到爱不释手。嘻嘻~。我们不仅可以使用docker还可以安装很多实用的工具，你可以到dockerHub上去查找你需要的镜像。 准备工作安装Docker无论你是Windows还是Mac还是Linux，现在网上都有很多安装教程，你可以根据步骤进行安装，这里我们就当Docker已经安装完啦。 拉取mysql的镜像(这里使用mysql5.7)1$ docker pull mysql:5.7 启动mysql当我们从镜像仓库拉完mysql以后，本地或者服务器上就已经有了mysql的镜像，我们可以通过命令去查看1$ docker images 这个命令就列出了当前主机上已经下载的所有镜像。 在宿主机上创建数据存储文件夹个人比较推荐使用docker安装镜像之后对于数据要有规律的去保存，这样也方便以后删除镜像的时候能够轻易的找到数据一起删除。所有在这里我所有使用docker安装的镜像都会在/data/docker目录下，docker目录中暗中镜像再进行分类。例如：这里我要使用docker启动一个mysql的容器 容器名称为mysql001，这样我就创建如下目录1$ mkdir /data/docker/mysql/mysql001 创建容器1$ docker run --name mysql001 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -v /etc/localtime:/etc/localtime -v /data/docker/mysql/mysql001:/var/lib/mysql -d mysql:5.7 这里我们对上面的命令进行拆解，清楚的了解每一步都是在做什么操作。 docker run这是启动一个容器 –name mysql001启动的容器名称为mysql001，这个名称在后面操作可直接使用名称 -p 3306:3306映射端口，前面一个端口是宿主机的端口，后面一个端口是mysql的端口，我们访问数据库是通过访问宿主机去访问，所以使用的是前面一个端口 -e MYSQL_ROOT_PASSWORD=root设置mysql的登录密码为root -v /etc/localtime:/etc/localtime这个是这是启动容器的时区和宿主机一致，这个设置比较有用，不然会出现数据库中的时间比当前时间晚8小时 -v /data/docker/mysql/mysql001:/var/lib/mysql这个就是用刚刚创建的目录去存储mysql的数据了，我们在mysql中的所有数据都会存储在宿主器前面的目录里 -d mysql:5.7这个是知道启动容器的版本 如果没有的话默认就是latest 和前面pull镜像时一样 启动容器执行完上面的命令后容器并没有启动，我们可以通过执行以下命令去启动容器1$ docker start mysql001 或者将name修改为image_id，image_id可以通过 docker images命令去查看。 访问mysql数据库 方式一 1$ mysql-cli -h 127.0.0.1 -u root -p root 方式二使用mysql客户端如：mysqlworkbatch，navicat等客户端软件。 删除容器删除容器必须要保证容器是stop的可以通过下面的命令查看 查看正在运行的容器 1$ docker ps 查看所有运行过的容器包括正在运行的容器 1$ docker ps -a 根据上面的命令可以查找到容器id，执行命令删除容器1$ docker rm 容器id]]></content>
      <categories>
        <category>Docker</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-01-docker介绍]]></title>
    <url>%2F2019%2F03%2F06%2Fdocker%2Fdocker-01-docker%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Docker介绍什么是Docker？Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及 AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为##容器##。 Docker在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker技术比虚拟机技术更为轻便、快捷。 传统虚拟机技术是虚拟 出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程;而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 为什么要使用docker？作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间传统的虚拟机技术启动应用服务往往需要数分钟，而Docker容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启 动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug并未在开发过程中被发现。而Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 “这段代码 在我机器上没问题啊” 这类问题。 持续交付和部署使用Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过Dockerfile来进行镜像构建，并结合持续集成(Continuous Integration)系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment)系统进行自动部署。 更轻松的迁移由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker团队同各个开源项目团队一起维护了一大批高质量的官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 对比传统虚拟机总结特性 | 容器 | 虚拟机:–: | :–: | :–:启动 | 秒级 | 分钟级硬盘使用 | 一般为MB | 一般为GB性能 | 接近原生 | 弱于系统支持量 | 单机支持上千个容器 | 一般几十个 Docker的几个基本概念Docker镜像(image)我们都知道，操作系统分为内核和用户空间。对于Linux而言，内核启动后，会挂载文件系统为其提供用户空间支持。而Docker镜像(Image)，就相当于是一个文件系统。比如官方镜像ubuntu:14.04就包含了完整的一套Ubuntu14.04最小系统的root文件系统。 因为镜像包含操作系统完整的root文件系统，其体积往往是庞大的，因此在Docker设计时，就充分利用UnionFS的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个ISO那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说是由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 Docker容器(container)镜像(image)和容器(container)的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但是与直接在宿主机上执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的root文件系统、自己的网络配置、自己的进程空间，甚至自己的用户ID空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷(Volume)、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器可以随意删除、重新run，数据却不会丢失。 Docker仓库(registry)镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。 下面以Ubuntu镜像为例，ubuntu是仓库的名字，其内包含有不同的版本标签，如:14.04,16.04。 我们可以通过ubuntu:14.04或者ubuntu:16.04来具体指定所需哪个版本的镜像。如果忽略了标签，那将视为ubuntu:latest。 公有仓库最常使用的公有仓库是DockerHub，这也是默认的仓库，拥有大量的官方镜像。还有还有CoreOS的Quay.io，Google的Google Container Registry，Kubernetes 的镜像使用的就是Google的服务。 由于某些原因，在国内访问这些服务可能会比较慢。国内的一些云服务商提供了针对Docker Hub的镜像服务(Registry Mirror)，这些镜像服务被称为加速器。常见的有:阿里云加速器、DaoCloud加速器、灵雀云加速器等。 私有仓库用户还可以在本地搭建私有Docker Registry。Docker官方提供了Docker Registry镜像，可以直接使用做为私有Registry服务。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ实战]]></title>
    <url>%2F2018%2F11%2F27%2FRabbitMQ%2F</url>
    <content type="text"><![CDATA[消息中间件什么是消息中间消息 (Message) 是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串、JSON 等，也可以很复杂，比如内嵌对象。 消息队列中间件 (Message Queue Middleware，简称为 MQ) 是指利用高效可靠的消息传递 机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传 递和消息排队模型，它可以在分布式环境下扩展进程间的通信。 消息队列中间件，也可以称为消息队列或者消息中间件。它一般有两种传递模式:点对点(P2P, Point-to-Point) 模式和发布/订阅 (Pub/Sub) 模式。点对点模式是基于队列的，消息生产 者 发送消息到队列，消息消费者从队列中接收消息，队列的存在使得消息的异步传输成为可能。 发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题 (topic)，主 题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者则从主题中 订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消 息的传递，发布/订阅模式在消息的一对多广播时采用 。 目前开源的消息中间件有很多，比较主流的有 RabbitMQ、 Kafka、 ActiveMQ、 RocketMQ 等。 消息中间件的作用消息中间件凭借其独到的特性，在不同的应用场景下可以展现不同的作用 。总 的来说，消息中间件的作用可以概括如下。 解耦在项目启动之初来预测将来会碰到什么需求是极其困难的。消息中间件在处理过程 中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，这允许你独 立地扩展或修改两边的处理过程，只要确保它 们遵守同样的接口约束即可。 冗余〈存储)有些情况下，处理数据的过程会失败。消息中间件可以把数据进行持久化直 到它们已经被完全处理，通过这一方式规避了数据丢失风险。在把一个消息从消息中间件中删除之前，需要你的处理系统明确地指出该消息己经被处理完成，从而确保你的数据被安全地保 存直到你使用完毕。 扩展性因为消息中间件解捐了应用的处理过程，所以提高消息入队和处理的效率是很容易的，只要另外增加处理过程即可，不需要改变代码，也不需要调节参数。 削峰在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果以能处理这类峰值为标准而投入资源，无疑是巨大的浪费。使用消息中间件能够使关键组件支撑突发访问压力，不会因为突发的超负荷请求而完全崩惯。 可恢复性当系统一部分组件失效时，不会影响到整个系统。消息中间件降低了进程间的稿合度，所以即使一个处理消息的进程挂掉，加入消息中间件中的消息仍然可以在系统恢复后 进行处理。 顺序保证在大多数使用场景下，数据处理的顺序很重要，大部分消息中间件支持一定程度上的顺序性。 缓冲在任何重要的系统中，都会存在需要不同处理时间的元素。消息中间件通过一个缓冲层来帮助任务最高效率地执行，写入消息中间件的处理会尽可能快速。该缓冲层有助于控制 和优化数据流经过系统的速度。 异步通信在很多时候应用不想也不需要立即处理消息 。消息中间件提供了异步处理机制，允许应用把一些消息放入消息中间件中，但并不立即处理它，在之后需要的时候再慢慢处理。 RabbitMQ入门RabbitMQ介绍RabbitMQ 是采用 Erlang 语言实现 AMQP (Advanced Message Queuing Protocol，高级消息队列协议)的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。并且支持多种客户端 如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。在易用性、扩展性、高可用性等方面表现不俗。 RabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。 AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。 RabbitMQ安装 使用docker安装(3-management版本自带管理后台) 1$ docker pull rabbitmq:3-management 启动rabbitMQ并且启动管理后台 123$ docker run -d -p 15672:15672 -p 5672:5672 -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin --name rabbitmq --hostname=rabbitmqhostone rabbitmq:3-management$ docker start rabbitmq 查看管理后台在浏览器打开 http://localhost:15672/ 输入用户名:admin 密码:admin 可进入管理后台 相关概念介绍生产者和消费者 Producer:生产者，就是投递消息的一方。生产者创建消息，然后发布到 RabbitMQ 中。消息一般可以包含2个部分:消息体和标签(Label)。消息体也可以称之为payload，在实际应用中，消息体一般是一个带有业务逻辑结构的数据，比如一个JSON字符串。当然可以进一步对这个消息体进行序列化操作。消息的标签用来表述这条消息，比如一个交换器的名称和一个路由键。生产者把消息交由RabbitMQ，RabbitMQ 之后会根据标签把消息发送给感兴趣的消费者(Consumer)。 Consumer:消费者，就是接收消息的一方。消费者连接到RabbitMQ服务器，并订阅到队列上。当消费者消费一条消息时，只是消费消息的消息体(payload).在消息路由的过程中，消息的标签会丢弃，存入到队列中的消息只有消息体，消费者也只会消费到消息体，也就不知道消息的生产者是谁，当然消费者也不需要知道。 Broker:消息中间件的服务节点。对于RabbitMQ来说，一个RabbitMQBroker可以简单地看作一个RabbitMQ服务节点，或者RabbitMQ服务实例。大多数情况下也可以将一个RabbitMQ Broker看作一台RabbitMQ服务器。 RabbitMQ运转流程 交换器Exchange，路由RoutingKey，绑定Binding Exchange:交换器MQ中我们暂时可以理解成生产者将消息投递到队列中，但是实际上这个在RabbitMQ中不会发生。真实情况是，生产者将消息发送到Exchange(交换器)，由交换器将消息路由到一个或者多个队列中。如果路由不到，或许会返回给生产者，或许直接丢弃。RabbitMQ中的交换器有四种类型，下面会一一介绍，并且会使用代码详细说明。 RoutingKey:路由键生产者将消息发给交换器的时候，一般会指定一个RoutingKey，用来指定这个消息的路由规则，而这个RoutingKey需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效。在交换器类型和绑定键(BindingKey)固定的情况下，生产者可以在发送消息给交换器时，通过指定RoutingKey来决定消息流向哪里。 Binding:绑定RabbitMQ中通过绑定将交换器与队列关联起来，在绑定的时候 一般会指定一个绑定键(BindingKey)，这样RabbitMQ就知道如何正确地将消息路由到队列了，如下图所示: 交换器类型RabbitMQ 常用的交换器类型有fanout、direct、topic、headers这四种。AMQP协议里还提到另外两种类型:System和自定义，这里就不详细介绍了。 fanout就是我们熟悉的广播模式或者订阅模式，它会把所有发送到该ExChange的消息全部路由到所有与该交换器绑定的队列中。如下图： direct(默认的交换器类型)direct类型的交换器路由规则也很简单，它会把消息路由到那些 BindingKey和 RoutingKey 完全匹配的队列中。如下图： topic上面讲到direct类型的交换器路由规则是完全匹配BindingKey和RoutingKey，但是这种严格的匹配方式在很多情况下不能满足实际业务的需求。topic类型的交换器在匹配规则上进行了扩展，它与direct类型的交换器相似，也是将消息路由到BindingKey和RoutingKey相匹配的队列中，但这里的匹配规则有些不同，它约定: RoutingKey为一个点号”.”分隔的字符串(被点号”.”分隔开的每一段独立的字符串称为一个单词)，如”com.rabbitmq.client”，”java.util.concurrent”,”com.hidden.client”等 BindingKey也是点号”.”分隔 BindingKey中可以存在两种特殊字符串”星号”和”#”，用于做模糊匹配，其中”星号”用于匹配一个单词，”#”用于匹配多规格单词(可以是零个)。如下图：思考:1.路由建 “com.rabbitmq.client”会路由到哪一个队列？2.路由建 “com.hidden.client”会路由到哪一个队列？3.路由建 “com.hidden.demo”会路由到哪一个队列？4.路由建 “java.util.concurrent”会路由到哪一个队列？5.路由建 “java.rabbitmq.demo”会路由到哪一个队列？ headers(不常用)headers类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。在绑定队列和交换器时制定一组键值对，当发送消息到交换器时，RabbitMQ会获取到该消息的headers(也是一个键值对的形式)，对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers类型的交换器性能会很差，而且也不实用，基本上不会看到它的存在。 交换器类型详解###新建rabbit-demo工程，在其中新建两个mudle 一个为rabbit-consumer 另一个为rabbit-producerpom.xml12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; rabbit-producer/application.properties1234567server.port=1180# 端口 1181 消费者 1180 生产者spring.rabbitmq.host=127.0.0.1spring.rabbitmq.username=adminspring.rabbitmq.password=adminspring.rabbitmq.port=5672 rabbit-producer/application.properties1234567server.port=1181# 端口 1181 消费者 1180 生产者spring.rabbitmq.host=127.0.0.1spring.rabbitmq.username=adminspring.rabbitmq.password=adminspring.rabbitmq.port=5672 项目创建完成 声明一个队列各个参数的意义name: 队列的名称 字符串durable: 是否持久化, 队列的声明默认是存放到内存中的，如果rabbitmq重启会丢失，如果想重启之后还存在就要使队列持久化，保存到Erlang自带的Mnesia数据库中，当rabbitmq重启之后会读取该数据库exclusive: 是否排外的，有两个作用，一：当连接关闭时connection.close()该队列是否会自动删除；二：该队列是否是私有的private，如果不是排外的，可以使用两个消费者都访问同一个队列，没有任何问题，如果是排外的，会对当前队列加锁，其他通道channel是不能访问的，如果强制访问会报异常，一般等于true的话用于一个队列只能有一个消费者来消费的场景。autoDelete: 是否自动删除，当最后一个消费者断开连接之后队列是否自动被删除，可以通过RabbitMQ Management，查看某个队列的消费者数量，当consumers = 0时队列就会自动删除arguments: 队列中的消息什么时候会自动被删除？ 是一个Map&lt;String, Object&gt;，他有如下参数 “x-message-ttl”: 1000 设置队列中的所有消息的生存周期 “x-expires”: 1000 当队列在指定的时间没有被访问就会被删除 “x-max-length”: 10 限定队列的消息的最大值长度，超过指定长度将会把最早的几条删除掉 “x-max-length-bytes”: 限定队列最大占用的空间大小， 一般受限于内存、磁盘的大小 “x-dead-letter-exchange”: “” 当队列消息长度大于最大长度、或者过期的等，将从队列中删除的消息推送到指定的交换机中去而不是丢弃掉 “x-dead-letter-routing-key”: “” 将删除的消息推送到指定交换机的指定路由键的队列中去 “x-max-priority”: 优先级队列，声明队列时先定义最大优先级值(定义最大值一般不要太大)，在发布消息的时候指定该消息的优先级， 优先级更高（数值更大的）的消息先被消费 “x-queue-mode”: “lazy” 先将消息保存到磁盘上，不放在内存中，当消费者开始消费的时候才加载到内存中 “x-queue-master-locator” fanout代码实现在消费者项目中添加一个配置类12345678910111213141516171819202122232425262728293031323334353637383940414243package com.jiafly.rabbit.consumer.fanout;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.FanoutExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author liuyi * @date 2018/12/1 4:35 PM */@Configurationpublic class FanoutConfig &#123; // 声明一个队列，后面有很多属性 @Bean public Queue fanoutQueue1()&#123; return new Queue("fanout.queue1"); &#125; @Bean public Queue fanoutQueue2()&#123; return new Queue("fanout.queue2"); &#125; @Bean public FanoutExchange fanoutExchange()&#123; return new FanoutExchange("fanout_exchange"); &#125; @Bean public Binding fanoutBinding1()&#123; return BindingBuilder.bind(fanoutQueue1()).to(fanoutExchange()); &#125; @Bean public Binding fanoutBinding2()&#123; return BindingBuilder.bind(fanoutQueue2()).to(fanoutExchange()); &#125;&#125; 在消费者项目中添加一个消息监听类1234567891011121314151617181920212223242526272829package com.jiafly.rabbit.consumer.fanout;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;/** * @author liuyi * @date 2018/12/1 4:40 PM */@Component@Slf4jpublic class FanoutConsumer &#123; @RabbitListener(queues = "fanout.queue1") @RabbitHandler public void fanoutConsumer1(String msg)&#123; log.info("1fanoutConsumer 接收消息msg: &#123;&#125;", msg); &#125; @RabbitListener(queues = "fanout.queue2") @RabbitHandler public void fanoutConsumer2(String msg)&#123; log.info("2fanoutConsumer 接收消息msg: &#123;&#125;", msg); &#125;&#125; 在生产者项目中添加一个消息发送controller12345678910111213141516171819202122232425262728293031323334353637package com.jiafly.rabbit.producer;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author liuyi * @date 2018/11/28 11:50 AM * 生产者 */@RestController@RequestMapping()@Slf4jpublic class FanoutProducer &#123; @Autowired private AmqpTemplate template; /** * fanout类型 * @param msg 消息内容 * @return 消息内容 * 虽然fanout类型下不需要routingKey 但是在调用convertAndSend方法时还是需要配置routingKey * 只是routingKey可以任意指定 */ @RequestMapping("/fanout/&#123;msg&#125;") public String fanoutProducer(@PathVariable("msg") String msg)&#123; log.info("fanout生产消息 msg:&#123;&#125;", msg); // 第一个参数是交换器名称 第二个参数是routingKey名称，fanout模式写任何key都会被无视 第三个是要发送的消息 template.convertAndSend("fanout_exchange","", msg); return msg; &#125;&#125; 测试分别启动两个项目，在浏览器的路径上输入 http://localhost:1180/fanout/测试消息 ，就可在消费者项目控制台中看到绑定这个fanout模式交换器的队列接收到的消息在控制台打印出来了。 direct代码实现在消费者项目中添加一个配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.jiafly.rabbit.consumer.direct;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * @author liuyi * @date 2018/11/29 1:40 AM */@Configurationpublic class DirectConfig &#123; /** * 定义两个队列 * @return */ @Bean public Queue directQueue1() &#123; return new Queue("direct.queue1",true); &#125; @Bean public Queue directQueue2() &#123; return new Queue("direct.queue2", true); &#125; @Bean public Queue directQueue3() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16); return new Queue("direct.queue3",true,true, true, map); &#125; /** * 定义 exchange * @return */ @Bean public DirectExchange directExchange() &#123; return new DirectExchange("direct_exchange",true,true); &#125; /** * 队列1 绑定 exchange 并且设置routingKey为direct.1 * @return */ @Bean public Binding directBinding1()&#123; return BindingBuilder.bind(directQueue1()).to(directExchange()).with("direct.routing.key1"); &#125; /** * 队列2 绑定 exchange 并且设置routingKey为direct.2 * @return */ @Bean public Binding directBinding2()&#123; return BindingBuilder.bind(directQueue2()).to(directExchange()).with("direct.routing.key2"); &#125; @Bean public Binding directBinding3()&#123; return BindingBuilder.bind(directQueue3()).to(directExchange()).with("direct.routing.key1"); &#125;&#125; 在消费者项目中添加一个消息监听类1和fanout相同，只是监听的队列不同而已 在生产者项目中添加一个消息发送controller12345678910111213141516171819202122232425262728293031323334353637383940414243package com.jiafly.rabbit.producer;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author liuyi * @date 2018/11/28 11:50 AM * 生产者 */@RestController@RequestMapping()@Slf4jpublic class DirectProducer &#123; @Autowired private AmqpTemplate template; /** * direct类型 * @param msg 消息内容 * @return 消息内容 */ @RequestMapping("/direct/queue1/&#123;msg&#125;") public String directProducerOne(@PathVariable("msg") String msg) &#123; log.info("生产者生产消息:" + msg); // 第一个参数是交换器名称 第二个参数是routingKey名称 第三个是要发送的消息 template.convertAndSend("direct_exchange", "direct.routing.key1", msg); return msg; &#125; @RequestMapping("/direct/queue2/&#123;msg&#125;") public String directProducerTwo(@PathVariable("msg") String msg) &#123; log.info("生产者生产消息:" + msg); // 第一个参数是交换器名称 第二个参数是routingKey名称 第三个是要发送的消息 template.convertAndSend("mq-direct_exchange", "direct.routing.key2", msg); return msg; &#125;&#125; 测试分别启动两个项目，在浏览器的路径上输入 http://localhost:1180/direct/queue1/测试消息1 ，就可在消费者项目中看到打印的信息。如果需要两个队列接受相同的信息，只需要将两个队列绑定的routingKey设置为一样即可 topic代码实现在消费者项目中添加一个配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.jiafly.rabbit.consumer.topic;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author liuyi * @date 2018/11/29 8:42 AM */@Configurationpublic class TopicConfig &#123; /** * 创建队列 * * @return */ @Bean public Queue topicQueue1() &#123; return new Queue("topic.queue1", true); &#125; @Bean public Queue topicQueue2() &#123; return new Queue("topic.queue2", true); &#125; /** * 创建交换器 */ @Bean public TopicExchange topicExchange() &#123; return new TopicExchange("topic_exchange"); &#125; /** * 绑定 */ @Bean public Binding topicBinding1() &#123; return BindingBuilder.bind(topicQueue1()).to(topicExchange()).with("*.jiafly.*"); &#125; @Bean public Binding topicBinding2() &#123; return BindingBuilder.bind(topicQueue2()).to(topicExchange()).with("com.jiafly.*"); &#125;&#125; 在消费者项目中添加一个消息监听类1和fanout相同，只是监听的队列不同而已 在生产者项目中添加一个消息发送controller12345678910111213141516171819202122232425262728293031323334package com.jiafly.rabbit.producer;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author liuyi * @date 2018/11/28 11:50 AM * 生产者 */@RestController@RequestMapping()@Slf4jpublic class TopicProducer &#123; @Autowired private AmqpTemplate template; /** * topic类型 * @param msg 消息内容 * @return 消息内容 */ @RequestMapping("/topic/&#123;msg&#125;") public String topicProducerOne(@PathVariable("msg") String msg) &#123; log.info("topic:生产消息:" + msg); template.convertAndSend("topic_exchange", "com.jiafly.test", msg); return msg; &#125;&#125; 测试分别启动两个项目，在浏览器的路径上输入 http://localhost:1180/topic/测试消息 ，就可在消费者项目中看到打印的信息。如果需要两个队列接受相同的信息，只需要将两个队列绑定的routingKey使用*或者#表示 延时队列延时队列能做什么 订单业务：在电商/点餐中，都有下单后 30 分钟内没有付款，就自动取消订单。 短信通知：下单成功后 60s 之后给用户发送短信通知。 失败重试：业务操作失败后，间隔一定的时间进行失败重试 这类业务的特点就是：非实时的，需要延迟处理，需要进行失败重试。一种比较笨的方式是采用定时任务，轮训数据库，方法简单好用，但性能底下，在高并发情况下容易弄死数据库，间隔时间不好设置，时间过大，影响精度，过小影响性能，而且做不到按超时的时间顺序处理。另一种就是用Java中的DelayQueue 位于java.util.concurrent包下，本质是由PriorityQueue和BlockingQueue实现的阻塞优先级队列。，这玩意最大的问题就是不支持分布式与持久化。 在 AMQP 协议中，或者 RabbitMQ 本身没有直接支持延迟队列的功能，但是可以通过前面 所介绍的 DLX 和 TTL 模拟出延迟队列的功能。所以在介绍延时队列之前，首先介绍下DLX(Dead-Letter-Exchange)和TTL(Time to Live)。 死信交换器DLX(Dead-Letter-Exchange)DLX：死信队列，用来存储有超时时间信息的消息， 并且可以设置当消息超时时，转发到另一个指定队列(此处设置转发到router), 无消费者，当接收到客户端消息之后，等待消息超时，将消息转发到指定的Router队列。 Router: 转发队列，用来接收死信队列超时消息， 如上示例消息，在接收到之后，消费者将消息解析，获取queueName，body,再向所获取的queueName队列发送一条消息，内容为body. 具体代码实现: 在消费者项目中添加一个配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.jiafly.rabbit.consumer.delay;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.DirectExchange;import org.springframework.amqp.core.Queue;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;/** * @author liuyi * @date 2018/12/2 12:44 AM */@Configurationpublic class DelayConfig &#123; /** * 定义一个交换机 * * @return */ @Bean public DirectExchange delayExchange() &#123; return new DirectExchange("delay_exchange", true, false); &#125; /** * 转发队列 * * @return */ @Bean public Queue routerQueue() &#123; return new Queue("router.queue", true, false, false); &#125; /** * 转发队列绑定交换机 * * @return */ @Bean public Binding routerBinding() &#123; return BindingBuilder.bind(routerQueue()).to(delayExchange()).with("router.routing.key"); &#125; /** * 死信队列 * * @return */ @Bean public Queue deadLetterQueue() &#123; HashMap&lt;String, Object&gt; arguments = new HashMap(16); arguments.put("x-dead-letter-exchange", "delay_exchange"); arguments.put("x-dead-letter-routing-key", "router.routing.key"); return new Queue("dead.letter.queue", true, false, false, arguments); &#125; /** * 死信队列绑定交换机 * * @return */ @Bean public Binding deadLetterBinding() &#123; return BindingBuilder.bind(deadLetterQueue()).to(delayExchange()).with("dead.letter.routing.key"); &#125;&#125; 在消费者项目中添加一个消息监听类123456789101112131415161718192021package com.jiafly.rabbit.consumer.delay;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;/** * @author liuyi * @date 2018/12/3 6:13 PM */@Component@Slf4jpublic class DelayConsumer &#123; @RabbitListener(queues = "router.queue") @RabbitHandler public void delayConsumer(String msg) &#123; log.info("delay.queue1接收消息:&#123;&#125;", msg); &#125;&#125; 在生产者项目中添加一个消息发送controller12345678910111213141516171819202122232425262728293031323334353637package com.jiafly.rabbit.producer;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.amqp.support.converter.AbstractJavaTypeMapper;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author liuyi * @date 2018/12/3 7:17 PM */@RestController@RequestMapping()@Slf4jpublic class DelayProducer &#123; @Autowired private AmqpTemplate template; /** * 延迟队列 * @param msg 消息内容 * @return 消息内容 */ @RequestMapping("/delay/&#123;msg&#125;") public String delayProducerOne(@PathVariable("msg") String msg) &#123; log.info("delay:生产消息:" + msg); template.convertAndSend("delay_exchange", "dead.letter.routing.key", msg, message -&gt; &#123; message.getMessageProperties().setExpiration(30 * 1000 + ""); return message; &#125;); return msg; &#125;&#125; 测试分别启动两个项目，在浏览器的路径上输入 http://localhost:1180/delay/测试消息 ，就可在消费者项目中看到打印的信息。 30秒后可以看到消费者管理后台有刚刚发送的消息被打印出来了。 消息的持久化为了保证RabbitMQ在重启、奔溃等异常情况下数据没有丢失，除了对消息本身持久化为，还需要将消息传输经过的队列(queue)，交互机进行持久化(exchange)，持久化以上元素后，消息才算真正RabbitMQ重启不会丢失。创建时候的参数: durable是否持久化，如果true，则此种队列叫持久化队列（Durable queues）。此队列会被存储在磁盘上，当消息代理（broker）重启的时候，它依旧存在。没有被持久化的队列称作暂存队列（Transient queues）。 execulusive表示此对应只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable autoDelete当没有生成者/消费者使用此队列时，此队列会被自动删除。(即当最后一个消费者退订后即被删除) 设置消息持久化必须先设置队列持久化，要不然队列不持久化，消息持久化，队列都不存在了，消息存在还有什么意义。消息持久化需要将交换机持久化、队列持久化、消息持久化，才能最终达到持久化的目的。其实在前面就已经使用持久化了。我们在管理后台去看一下。 消息的确认与拒绝消费者在处理消息的时候偶尔会失败或者有时会直接崩溃掉。而且网络原因也有可能引起各种问题，对于此AMQP有两种处理方式： 自动确认模式:当RabbbitMQ将消息发送给应用后，消费者端自动回送一个确认消息，此时RabbitMQ删除此消息。 显式确认模式:消费者收到消息后，可以在执行一些逻辑后，消费者自己决定什么时候发送确认回执（acknowledgement），RabbitMQ收到回执后才删除消息，这样就保证消费端不会丢失消息 如果一个消费者在尚未发送确认回执的情况下挂掉了，那么消息会被重新放入队列，并且在还有其他消费者存在于此队列的前提下，立即投递给另外一个消费者。如果当时没有可用的消费者了，消息代理会死等下一个注册到此队列的消费者，然后再次尝试投递。RabbitMQ里的消息是不会过期。当消费者挂掉后，RabbitMQ会不断尝试重推。所有单个消息的推送可能花费很长的时间.]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
</search>
